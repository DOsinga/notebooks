{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Style Transfer Interpolation\n",
    "\n",
    "Modified version of the https://github.com/fchollet/keras/blob/master/examples/neural_style_transfer.py neural style transfer. Rather than having one style image, we have two. We first train the network for a number of iterations to get to converge on the first image, before interpolating for the rest of the iterations between the first and the second.\n",
    "\n",
    "Interpolation is done by having step variable that controls the weight of the loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from scipy.misc import imsave\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "import os\n",
    "import imageio\n",
    "from IPython.display import Image, display, HTML\n",
    "\n",
    "from keras.applications import vgg16\n",
    "from keras import backend as K\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some functions to convert from and to the internal format used. Make sure we end up with images of the right size and take care of the colors being at the position that the selected back end expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=(img_nrows, img_ncols))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg16.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "\n",
    "\n",
    "def deprocess_image(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((3, img_nrows, img_ncols))\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    else:\n",
    "        x = x.reshape((img_nrows, img_ncols, 3))\n",
    "    # Remove zero-center by mean pixel\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the three images we need from the Internet if they aren't already loaded. Base Image is the image that we'll render a style transfered version of, style reference 1 & 2 are the style images to interpolate between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "IMAGE_BASE = 'style_transfer/'\n",
    "\n",
    "def fetch_image(url, fn=None):\n",
    "    if not fn:\n",
    "        fn = url.rsplit('/', 1)[-1]\n",
    "    fn = IMAGE_BASE + fn\n",
    "    if os.path.isfile(fn):\n",
    "        return fn\n",
    "    img = requests.get(url).content\n",
    "    with open(fn, 'wb') as fout:\n",
    "        fout.write(img)\n",
    "    return fn\n",
    "\n",
    "base_image_path = fetch_image('https://upload.wikimedia.org/wikipedia/commons/0/08/Okerk2.jpg')\n",
    "style_reference_image_path_2 = fetch_image('https://upload.wikimedia.org/wikipedia/commons/9/99/Jan_van_Goyen_004b.jpg')\n",
    "style_reference_image_path_1 = fetch_image('https://upload.wikimedia.org/wikipedia/commons/6/66/VanGogh-starry_night_ballance1.jpg')\n",
    "Image(filename=base_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some working variables and constants we are going to need. Change img_nrows to influence the size of the output picture. The various *_weight variables will determine how much influence the three loss functions have (see below). Iterations is the total of number of iterations, the first warm_up will be used to get to a stable version of the image, the rest will be used for the interpolation frames. result_prefix is the prefix used for the intermediate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "width, height = load_img(base_image_path).size\n",
    "img_nrows = 400\n",
    "img_ncols = int(width * img_nrows / height)\n",
    "\n",
    "total_variation_weight = 1.0\n",
    "style_weight = 1.0\n",
    "content_weight = 0.025\n",
    "\n",
    "iterations = 120\n",
    "warm_up = 30\n",
    "\n",
    "result_prefix = 'star_goyen'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the images into three variables and create a place holder for the resulting combination image. Then create a tensor that contains all four of them next to each other so we can process them together in the same way as we'd process a mini-batch when training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concat_1:0' shape=(4, 400, 632, 3) dtype=float32>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_image = K.variable(preprocess_image(base_image_path))\n",
    "style_reference_image_1 = K.variable(preprocess_image(style_reference_image_path_1))\n",
    "style_reference_image_2 = K.variable(preprocess_image(style_reference_image_path_2))\n",
    "\n",
    "# this will contain our generated image\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    combination_image = K.placeholder((1, 3, img_nrows, img_ncols))\n",
    "else:\n",
    "    combination_image = K.placeholder((1, img_nrows, img_ncols, 3))\n",
    "\n",
    "# combine the 4 images into a single Keras tensor\n",
    "input_tensor = K.concatenate([base_image,\n",
    "                              style_reference_image_1,\n",
    "                              style_reference_image_2,\n",
    "                              combination_image], axis=0)\n",
    "input_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now load the pretrained vgg16 model and load it up with the four images as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded.\n"
     ]
    }
   ],
   "source": [
    "model = vgg16.VGG16(input_tensor=input_tensor,\n",
    "                    weights='imagenet', include_top=False)\n",
    "print('Model loaded.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple helper dictionary to get to the outputs of the layers in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "outputs_dict = {layer.name: layer.output for layer in model.layers}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The clever bit\n",
    "\n",
    "Now for the clever bit. We define three loss functions that we combine into one overall loss function to optimize. Each of the three. Each of the three functions tries to control one aspect of the process:\n",
    "\n",
    "* Style loss - keep the style of the target image close to the style we selected\n",
    "* Content loss - keep the overall image similar to the base image\n",
    "* Variation - supress local variation to keep the image locally coherent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Style loss\n",
    "\n",
    "We need two functions. gram_matrix calculates the feature activiation of an image by taking the outer product of a particular layer. We then calculate the style loss between our target image and the source of the style summing the squares of the gram matrix for these images scaled for the size of the tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gram_matrix(x):\n",
    "    assert K.ndim(x) == 3\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        features = K.batch_flatten(x)\n",
    "    else:\n",
    "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_nrows * img_ncols\n",
    "    return K.sum(K.square(S - C)) / (4. * (channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Content loss\n",
    "\n",
    "Content is the straight forward sum of squares between the base and the target image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Variation Loss\n",
    "\n",
    "Minimize the local variation by comparing effectively pixels next to each other and minimizing the variation. This keeps the resulting image somewhat fuzzy, but it avoids large jumps in the pixels and keeps the image locally coherent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    assert K.ndim(x) == 4\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
    "        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The combined loss function\n",
    "\n",
    "Now combine the three loss functions from above into one combined one that we can optimize for. We use selected layers from the neural network for style and content loss, while the variation loss is calculated on just the resulting image.\n",
    "\n",
    "We introduce an extra place holder variable \"step\" indicating where we are transitioning from one style to another and calculate the style loss for both style images and scale the result accordingly between these two loss values. Finally calculate the gradient with regard to the combination image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "loss = K.variable(0.)\n",
    "layer_features = outputs_dict['block4_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[3, :, :, :]\n",
    "loss += content_weight * content_loss(base_image_features,\n",
    "                                      combination_features)\n",
    "step = K.placeholder()\n",
    "feature_layers = ['block1_conv1', 'block2_conv1',\n",
    "                  'block3_conv1', 'block4_conv1',\n",
    "                  'block5_conv1']\n",
    "for layer_name in feature_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features_1 = layer_features[1, :, :, :]\n",
    "    style_reference_features_2 = layer_features[2, :, :, :]\n",
    "    combination_features = layer_features[3, :, :, :]\n",
    "    sl_1 = style_loss(style_reference_features_1, combination_features) * step\n",
    "    sl_2 = style_loss(style_reference_features_2, combination_features) * (1 - step)\n",
    "    loss += (style_weight / len(feature_layers)) * (sl_1 + sl_2)\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)\n",
    "\n",
    "# get the gradients of the generated image wrt the loss\n",
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image, step], outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evalutor object\n",
    "\n",
    "Some extra plumbing to make it possible to use the above in combination with fmin_l_bfgs_b. Scipy.optimize requires two seperate loss and grads functions so rather than calculating those twice, we cache the values in an Evaluator object. We use the same object to store the value of where we are between the two style images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def eval_loss_and_grads(x, perc):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((1, 3, img_nrows, img_ncols))\n",
    "    else:\n",
    "        x = x.reshape((1, img_nrows, img_ncols, 3))\n",
    "    outs = f_outputs([x, perc])\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "class Evaluator(object):\n",
    "\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "        self.perc = 0\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x, self.perc)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model\n",
    "\n",
    "Now run the model. We start with a randomized image and then use the scipy-based L-BFGS algorithm to optimize the pixels. The first number of \"warm_up\" iterations we just target the first style image. After that we start to interpolate. While interpolating we store the name of the intermediate image in the frames variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start of iteration 0 0\n",
      "Current loss value: 2.77769e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_0.png\n",
      "Iteration 0 completed in 311s\n",
      "Start of iteration 1 0\n",
      "Current loss value: 2.19096e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_1.png\n",
      "Iteration 1 completed in 291s\n",
      "Start of iteration 2 0\n",
      "Current loss value: 1.96724e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_2.png\n",
      "Iteration 2 completed in 292s\n",
      "Start of iteration 3 0\n",
      "Current loss value: 1.84749e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_3.png\n",
      "Iteration 3 completed in 292s\n",
      "Start of iteration 4 0\n",
      "Current loss value: 1.77549e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_4.png\n",
      "Iteration 4 completed in 292s\n",
      "Start of iteration 5 0\n",
      "Current loss value: 1.7281e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_5.png\n",
      "Iteration 5 completed in 312s\n",
      "Start of iteration 6 0\n",
      "Current loss value: 1.69238e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_6.png\n",
      "Iteration 6 completed in 292s\n",
      "Start of iteration 7 0\n",
      "Current loss value: 1.66306e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_7.png\n",
      "Iteration 7 completed in 293s\n",
      "Start of iteration 8 0\n",
      "Current loss value: 1.64026e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_8.png\n",
      "Iteration 8 completed in 292s\n",
      "Start of iteration 9 0\n",
      "Current loss value: 1.62088e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_9.png\n",
      "Iteration 9 completed in 300s\n",
      "Start of iteration 10 0\n",
      "Current loss value: 1.60472e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_10.png\n",
      "Iteration 10 completed in 301s\n",
      "Start of iteration 11 0\n",
      "Current loss value: 1.59089e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_11.png\n",
      "Iteration 11 completed in 293s\n",
      "Start of iteration 12 0\n",
      "Current loss value: 1.5785e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_12.png\n",
      "Iteration 12 completed in 292s\n",
      "Start of iteration 13 0\n",
      "Current loss value: 1.56806e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_13.png\n",
      "Iteration 13 completed in 292s\n",
      "Start of iteration 14 0\n",
      "Current loss value: 1.55861e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_14.png\n",
      "Iteration 14 completed in 305s\n",
      "Start of iteration 15 0\n",
      "Current loss value: 1.55002e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_15.png\n",
      "Iteration 15 completed in 297s\n",
      "Start of iteration 16 0\n",
      "Current loss value: 1.54235e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_16.png\n",
      "Iteration 16 completed in 293s\n",
      "Start of iteration 17 0\n",
      "Current loss value: 1.53529e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_17.png\n",
      "Iteration 17 completed in 292s\n",
      "Start of iteration 18 0\n",
      "Current loss value: 1.52888e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_18.png\n",
      "Iteration 18 completed in 293s\n",
      "Start of iteration 19 0\n",
      "Current loss value: 1.52311e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_19.png\n",
      "Iteration 19 completed in 306s\n",
      "Start of iteration 20 0\n",
      "Current loss value: 1.51797e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_20.png\n",
      "Iteration 20 completed in 294s\n",
      "Start of iteration 21 0\n",
      "Current loss value: 1.51328e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_21.png\n",
      "Iteration 21 completed in 293s\n",
      "Start of iteration 22 0\n",
      "Current loss value: 1.50881e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_22.png\n",
      "Iteration 22 completed in 292s\n",
      "Start of iteration 23 0\n",
      "Current loss value: 1.50453e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_23.png\n",
      "Iteration 23 completed in 293s\n",
      "Start of iteration 24 0\n",
      "Current loss value: 1.50043e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_24.png\n",
      "Iteration 24 completed in 310s\n",
      "Start of iteration 25 0\n",
      "Current loss value: 1.49666e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_25.png\n",
      "Iteration 25 completed in 292s\n",
      "Start of iteration 26 0\n",
      "Current loss value: 1.493e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_26.png\n",
      "Iteration 26 completed in 293s\n",
      "Start of iteration 27 0\n",
      "Current loss value: 1.48948e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_27.png\n",
      "Iteration 27 completed in 293s\n",
      "Start of iteration 28 0\n",
      "Current loss value: 1.48604e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_28.png\n",
      "Iteration 28 completed in 293s\n",
      "Start of iteration 29 0\n",
      "Current loss value: 1.48271e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_29.png\n",
      "Iteration 29 completed in 307s\n",
      "Start of iteration 30 0\n",
      "Current loss value: 1.47949e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_30.png\n",
      "Iteration 30 completed in 293s\n",
      "Start of iteration 31 0.011235955056179775\n",
      "Current loss value: 2.38148e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_31.png\n",
      "Iteration 31 completed in 293s\n",
      "Start of iteration 32 0.02247191011235955\n",
      "Current loss value: 3.26933e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_32.png\n",
      "Iteration 32 completed in 293s\n",
      "Start of iteration 33 0.033707865168539325\n",
      "Current loss value: 4.14178e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_33.png\n",
      "Iteration 33 completed in 293s\n",
      "Start of iteration 34 0.0449438202247191\n",
      "Current loss value: 4.99854e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_34.png\n",
      "Iteration 34 completed in 309s\n",
      "Start of iteration 35 0.056179775280898875\n",
      "Current loss value: 5.83909e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_35.png\n",
      "Iteration 35 completed in 293s\n",
      "Start of iteration 36 0.06741573033707865\n",
      "Current loss value: 6.6628e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_36.png\n",
      "Iteration 36 completed in 293s\n",
      "Start of iteration 37 0.07865168539325842\n",
      "Current loss value: 7.46884e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_37.png\n",
      "Iteration 37 completed in 293s\n",
      "Start of iteration 38 0.0898876404494382\n",
      "Current loss value: 8.25536e+09\n",
      "Image saved as style_transfer/star_goyen_at_iteration_38.png\n",
      "Iteration 38 completed in 301s\n",
      "Start of iteration 39 0.10112359550561797\n"
     ]
    }
   ],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    x = np.random.uniform(0, 255, (1, 3, img_nrows, img_ncols)) - 128.\n",
    "else:\n",
    "    x = np.random.uniform(0, 255, (1, img_nrows, img_ncols, 3)) - 128.\n",
    "\n",
    "\n",
    "frames = []\n",
    "for i in range(0, iterations):\n",
    "    start_time = time.time()\n",
    "    if i > warm_up:\n",
    "        frames.append(fname)\n",
    "        evaluator.perc = float(i - warm_up) / (iterations - warm_up - 1)\n",
    "    else:\n",
    "        evaluator.perc = 0\n",
    "    print('Start of iteration', i, evaluator.perc)\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(),\n",
    "                                     fprime=evaluator.grads, maxfun=20)\n",
    "    print('Current loss value:', min_val)\n",
    "    # save current generated image\n",
    "    img = deprocess_image(x.copy())\n",
    "    fname = IMAGE_BASE + result_prefix + '_at_iteration_%d.png' % i\n",
    "    imsave(fname, img)\n",
    "    end_time = time.time()\n",
    "    print('Image saved as', fname)\n",
    "    print('Iteration %d completed in %ds' % (i, end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To display the result as an animated gif, we create a cycle from the frames variable and then use imageio to crate an animated gif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://douweosinga.com/static/projects/style_transfer/style_transfer.gif\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cycled = frames + list(reversed(frames[1:-1]))\n",
    "# Save them as frames into a gif \n",
    "kargs = { 'duration': 0.1 }\n",
    "imageio.mimsave(IMAGE_BASE + 'animated.gif', [imageio.imread(x) for x in cycled], 'GIF', **kargs)\n",
    "\n",
    "HTML('<img src=\"%s\">' % (IMAGE_BASE + 'animated.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
